<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Community Health Toolkit â€“ Hosting</title><link>https://docs.communityhealthtoolkit.org/apps/guides/hosting/</link><description>Recent content in Hosting on Community Health Toolkit</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/index.xml" rel="self" type="application/rss+xml"/><item><title>Apps: Requirements</title><link>https://docs.communityhealthtoolkit.org/apps/guides/hosting/requirements/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/apps/guides/hosting/requirements/</guid><description>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
For production CHT deployments, Linux is recommended, with &lt;a href="https://ubuntu.com/server">Ubuntu&lt;/a> the most commonly used. For CHT development, Linux or macOS may be used. Windows can be used for either, but without recommendation.
&lt;/div>
&lt;p>Hosting a CHT instance in a cloud provider like AWS or on bare-metal requires you have sufficient hardware specifications, Docker and Docker Compose installed and other infrastructure requirements met.&lt;/p>
&lt;h2 id="hardware-requirements">Hardware Requirements&lt;/h2>
&lt;ul>
&lt;li>4 GiB RAM&lt;/li>
&lt;li>2 CPU/vCPU&lt;/li>
&lt;li>8 GB Hard Disk (SSD prefered)&lt;/li>
&lt;li>SSL certificates ( To be able to use the CHT app on mobile)&lt;/li>
&lt;li>Root Access&lt;/li>
&lt;/ul>
&lt;p>Depending on the scale of your operation these may need to be adjusted. Be sure to monitor disk usage so that the 8 GB can be increased as needed.&lt;/p>
&lt;h2 id="docker">Docker&lt;/h2>
&lt;p>Install both &lt;code>docker&lt;/code> and &lt;code>docker-compose&lt;/code> to run the two &lt;code>medic-os&lt;/code> and &lt;code>haproxy&lt;/code> containers.&lt;/p>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
Skip this step if you&amp;rsquo;re following the &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/ec2-setup-guide/#create-and-configure-ec2-instance">EC2 guide&lt;/a> as &lt;code>docker&lt;/code> and &lt;code>docker-compose&lt;/code> are automatically installed when following the setup scripts.
&lt;/div>
&lt;h3 id="linux">Linux&lt;/h3>
&lt;p>Depending on which distro you run, install the Docker packages from &lt;a href="https://docs.docker.com/engine/install/#server">Docker&amp;rsquo;s Linux options&lt;/a>. Historically, Medic runs Ubuntu: see &lt;a href="https://docs.docker.com/engine/install/ubuntu/">Docker CE&lt;/a> and &lt;a href="https://docs.docker.com/compose/install/">Docker-compose&lt;/a> install pages.&lt;/p>
&lt;h3 id="windows">Windows&lt;/h3>
&lt;p>Docker Desktop for Windows needs either Hyper-V support or Windows Subsystem for Linux 2 (WSL 2). &lt;a href="https://docs.docker.com/docker-for-windows/install/">Docker&amp;rsquo;s Windows Docker Desktop install page&lt;/a> covers both scenarios.&lt;/p>
&lt;h3 id="macos">macOS:&lt;/h3>
&lt;p>See &lt;a href="https://docs.docker.com/docker-for-mac/install/">Docker&amp;rsquo;s macOS Docker Desktop install page&lt;/a>.&lt;/p>
&lt;h3 id="verify-install">Verify install&lt;/h3>
&lt;p>Test that &lt;code>docker&lt;/code> and &lt;code>docker-compose&lt;/code> installed correctly by showing their versions with &lt;code>sudo docker-compose --version&lt;/code> and &lt;code>sudo docker --version&lt;/code>. Note, your version may be different:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">
sudo docker-compose --version
docker-compose version 1.27.1, build 509cfb99
sudo docker --version
Docker version 19.03.12, build 48a66213fe
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Finally, confirm you can run the &amp;ldquo;hello world&amp;rdquo; docker container: &lt;code>sudo docker run hello-world&lt;/code>&lt;/p>
&lt;h2 id="considerations">Considerations&lt;/h2>
&lt;p>There are serious implications to consider when deploying a CHT instance beyond the above requirements. Be sure to account for:&lt;/p>
&lt;ul>
&lt;li>Alerting - How will alerts be sent in the case of downtime or degraded service?&lt;/li>
&lt;li>Power failures and unplanned restarts - Will the server cleanly restart such that the CHT resumes service correctly?&lt;/li>
&lt;li>Backups - What happens to the CHT data if there&amp;rsquo;s a hard drive failure?&lt;/li>
&lt;li>Disaster Recovery - What happens if there is a flood at the facility and on-site active and backup data are destroyed?&lt;/li>
&lt;li>Scale - What happens when the hardware deployed needs to be upgraded to increase capacity?&lt;/li>
&lt;li>Updates - By definition TLS certificates expire and software needs to be updated - how will the deployment get these updates on a regular basis?&lt;/li>
&lt;li>Security - While the TLS certificate will protect data on the LAN, is the server hard drive encrypted in the event of property theft?&lt;/li>
&lt;li>Privacy - The CHT inherently carries sensitive patient medical information in the database. Are there sufficient measures in place to protect this sensitive data?&lt;/li>
&lt;/ul></description></item><item><title>Apps: AWS Hosting</title><link>https://docs.communityhealthtoolkit.org/apps/guides/hosting/ec2-setup-guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/apps/guides/hosting/ec2-setup-guide/</guid><description>
&lt;p>Most production CHT instances are deployed on AWS EC2. Leveraging Elastic Compute Cloud (EC2) and Elastic Block Store (EBS), CHT instances can easily be scaled up with larger EC2 instances and have easy increased disk space, backup and restores with EBS.&lt;/p>
&lt;p>This guide will walk you through the process of creating an EC2 instance, mounting an EBS volume and provisioning Docker containers.&lt;/p>
&lt;h2 id="create-and-configure-ec2-instance">Create and Configure EC2 Instance&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Create EC2 (use security best practices)&lt;/p>
&lt;p>Review the &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/requirements/#hardware-requirements">CHT hardware requirements&lt;/a> and start with an appropriately sized instance. After creating the instance and downloading the &lt;code>.pem&lt;/code> file, change permissions to &lt;code>0600&lt;/code> for it:&lt;/p>
&lt;pre>&lt;code>sudo chmod 0600 ~/Downloads/name_of_file.pem
&lt;/code>&lt;/pre>&lt;p>Create an &lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/elastic-ip-addresses-eip.html">Elastic IP (EIP) and associate the EIP to your EC2 instance&lt;/a>.&lt;/p>
&lt;p>You should now be able to SSH into the EC2 instance using the EIP and the &lt;code>.pem&lt;/code> file.&lt;/p>
&lt;p>&lt;code>Goal&lt;/code>: SSH into instance&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create or Restore EBS Volume&lt;/p>
&lt;ul>
&lt;li>Create or &lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/ebs-restoring-volume.html">Restore&lt;/a> your EBS Volume, tagging appropriately, so it can be found later.&lt;/li>
&lt;li>Attach volume to EC2 instance&lt;/li>
&lt;li>&lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/recognize-expanded-volume-linux.html">Increase disk size&lt;/a> (Optional)&lt;/li>
&lt;li>If you are using a newly created EBS Volume, you will have to format the disk appropriately:
&lt;ol>
&lt;li>SSH into instance&lt;/li>
&lt;li>Follow the instructions here: &lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.html">Using EBS Volumes&lt;/a>&lt;/li>
&lt;li>Use &lt;code>sudo mkfs -t ext4 &amp;lt;location&amp;gt;&lt;/code> in step 4&lt;/li>
&lt;li>Mount disk to &lt;code>/srv&lt;/code>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;p>&lt;code>Goal&lt;/code>: Mount EBS volume to &lt;code>/srv&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Provision Docker server&lt;/p>
&lt;p>Follow README &amp;amp; Run scripts in &lt;a href="https://github.com/medic/cht-infrastructure/tree/master/self-hosting/prepare-system">cht-infrastructure repository&lt;/a>.&lt;/p>
&lt;p>&lt;code>Goal&lt;/code>: CHT Application bootstraps and comes online&lt;/p>
&lt;/li>
&lt;li>
&lt;p>DNS configuration&lt;/p>
&lt;ul>
&lt;li>Point DNS &lt;code>A&lt;/code> record to EIP given to Docker server in the prior step.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Review SSL certificates&lt;/p>
&lt;ul>
&lt;li>Location of certs is &lt;code>/srv/settings/medic-core/nginx/private/&lt;/code>&lt;/li>
&lt;li>Name the key file is &lt;code>default.key&lt;/code> and the certificate file is &lt;code>default.crt&lt;/code>&lt;/li>
&lt;li>See &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/ssl-cert-install/">SSL Certficates&lt;/a> to install new certificates&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Configure couch2pg
See the &lt;a href="https://github.com/medic/cht-couch2pg/blob/main/README.md">couch2pg basic configuration&lt;/a> in the &lt;code>cht-couch2pg&lt;/code> repository.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Setup postgres to work with couch2pg&lt;/p>
&lt;ul>
&lt;li>Creating the database, setting up permissions, exploring the tables and what they store&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Debugging couch2pg/postgres&lt;/p>
&lt;ul>
&lt;li>Understanding the log and what the entries mean&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="troubleshooting">Troubleshooting&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Restarting processes&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.communityhealthtoolkit.org/core/guides/docker-setup/#helpful-docker-commands">How to access container, retrieve logs, restart services&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/medic/medic-os#user-content-service-management-scripts">MedicOS service management scripts&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Investigating logs&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.communityhealthtoolkit.org/core/guides/docker-setup/#helpful-docker-commands">Helpful docker commands&lt;/a> (includes getting shell on containers)&lt;/li>
&lt;li>Inside container, all appropriate logs can be found in: &lt;code>/srv/storage/&amp;lt;service_name&amp;gt;/logs/*.log&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Upgrading the container&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Backup all data (EBS)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Log into container and stop all services&lt;/p>
&lt;/li>
&lt;li>
&lt;p>To prepare for the upgrade, delete all other files in &lt;code>/srv&lt;/code> EXCEPT for &lt;code>/srv/storage/medic-core/&lt;/code>&lt;/p>
&lt;p>The &lt;code>medic-core&lt;/code> directory is where the CHT stores user data. Of key importance is &lt;code>./couchdb/local.in&lt;/code> and &lt;code>./medic-core/couchdb/local.d/&lt;/code> where custom CouchDB configuration is stored.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://docs.communityhealthtoolkit.org/core/guides/docker-setup/#use-docker-compose">Change the image tag to the newest image release version&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://docs.communityhealthtoolkit.org/core/guides/docker-setup/#use-docker-compose">Change image tag in docker-compose file&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Launch new containers with appropriate &lt;code>COUCHDB_ADMIN_PASSWORD&lt;/code> &amp;amp; &lt;code>HA_PASSWORD&lt;/code> environment variables&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Upgrading the webapp&lt;/p>
&lt;ul>
&lt;li>Use Admin GUI page&lt;/li>
&lt;li>&lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/self-hosting/#links-to-medic-documentation-for-horticulturalist-for-upgrades">CLI via horticulturalist&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>RDS help&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Welcome.html">Amazon user guide&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="backups">Backups&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Configure backups&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html">EBS Snapshot Lifecycle Manager&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Restoring from backup&lt;/p>
&lt;ul>
&lt;li>Create volume from snapshot&lt;/li>
&lt;li>Tag appropriately for backups&lt;/li>
&lt;li>Mount volume to docker server&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="process-supervision">Process supervision&lt;/h2>
&lt;ul>
&lt;li>&lt;code>supvisorctl&lt;/code>&lt;/li>
&lt;li>&lt;code>/boot/supervisor-inspect&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="increasing-disk-size">Increasing disk size&lt;/h2>
&lt;p>Monitor disk usage so alerts are sent before all disk spaces is used up. If free disk space falls below 40%, increase the disk space as follows:&lt;/p>
&lt;ul>
&lt;li>Stop medic: &lt;code>sudo supervisorctl stop medic&lt;/code>&lt;/li>
&lt;li>Go to EBS in AWS and take a snapshot of the volume.&lt;/li>
&lt;li>Modify the volume size (Increase it by 2x preferably). Wait until the modification succeeds.&lt;/li>
&lt;li>&lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/recognize-expanded-volume-linux.html">Make the instance recognize the additional space&lt;/a>&lt;/li>
&lt;li>Turn medic back on: &lt;code>sudo supervisorctl start medic&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="monitoring--backup">Monitoring &amp;amp; Backup&lt;/h2>
&lt;ul>
&lt;li>AWS CloudWatch and monitoring tab. Enable detailed monitoring (This costs more money)&lt;/li>
&lt;li>Set up &lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snapshot-lifecycle.html#snapshot-lifecycle-console">Lifecycle Management for EBS snapshots&lt;/a>&lt;/li>
&lt;li>Steps to mounting a backup snapshot to the instance and restarting the application&lt;/li>
&lt;li>Please see the second-half of &amp;ldquo;Increasing disk size&amp;rdquo; reference above&lt;/li>
&lt;li>Setup a TLS cert &amp;amp; DNS registration&lt;/li>
&lt;/ul></description></item><item><title>Apps: Self Hosting</title><link>https://docs.communityhealthtoolkit.org/apps/guides/hosting/self-hosting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/apps/guides/hosting/self-hosting/</guid><description>
&lt;p>Whether run on bare-metal or in a cloud provider, the Community Health Toolkit (CHT) core framework has been packaged into a docker container to make it portable and easy to install. It is available from &lt;a href="https://hub.docker.com/r/medicmobile/medic-os">dockerhub&lt;/a>. To learn more how to work with docker you could follow the tutorial &lt;a href="https://docker-curriculum.com/#getting-started">here&lt;/a> and the cheat sheet &lt;a href="https://www.docker.com/sites/default/files/d8/2019-09/docker-cheat-sheet.pdf">here&lt;/a>.&lt;/p>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
Before continuing, ensure all &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/requirements/">requirements&lt;/a> are met.
&lt;/div>
&lt;h2 id="installing-with-a-compose-file">Installing with a compose file&lt;/h2>
&lt;p>The CHT containers are installed using &lt;a href="https://docs.docker.com/compose/reference/overview/">docker compose&lt;/a> so that you can run multiple containers as a single service.&lt;/p>
&lt;p>Start by choosing the location where you would like to save your compose configuration file. Then create the &lt;code>docker-compose.yml&lt;/code> file by &lt;code>cd&lt;/code>ing into the correct directory and running:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">curl -s -o docker-compose.yml https://raw.githubusercontent.com/medic/cht-core/master/docker-compose.yml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The install requires an admin password that it will configure in the database. You need to provide this externally as an environment variable. Before you run the compose file, you need to export this variable as shown below.&lt;/p>
&lt;p>&lt;code>export DOCKER_COUCHDB_ADMIN_PASSWORD=myAwesomeCHTAdminPassword&lt;/code>&lt;/p>
&lt;p>You can then run &lt;code>docker-compose&lt;/code> in the folder where you put your compose &lt;code>docker-compose.yml&lt;/code> file. To start, run it interactively to see all the logs on screen and be able to stop the containers with &lt;code>ctrl&lt;/code> + &lt;code>c&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sudo docker-compose up
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If there are no errors, stop the containers with &lt;code>ctrl&lt;/code> + &lt;code>c&lt;/code> and then run it detached with &lt;code>-d&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sudo docker-compose up -d
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note In certain shells, &lt;code>docker-compose&lt;/code> may not interpolate the admin password that was exported in &lt;code>DOCKER_COUCHDB_ADMIN_PASSWORD&lt;/code>. Check if this is the case by searching the logs in the medic-os dockers instance. If the &lt;code>docker logs medic-os&lt;/code> command below returns a user and password, then the export above failed, and you should use this user and password to complete the installation:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">docker logs medic-os &lt;span style="color:#000;font-weight:bold">|&lt;/span>grep &lt;span style="color:#4e9a06">&amp;#39;New CouchDB Admin&amp;#39;&lt;/span>
Info: New CouchDB Administrative User: medic
Info: New CouchDB Administrative Password: password
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Monitor the logs until you get the &lt;code>Setting up software (100% complete)&lt;/code> message. At this stage all containers are fully set up.&lt;/p>
&lt;p>Once containers are setup, please run the following command from your host terminal:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sudo docker &lt;span style="color:#204a87">exec&lt;/span> -it medic-os /bin/bash -c &lt;span style="color:#4e9a06">&amp;#34;sed -i &amp;#39;s/--install=3.9.0/--complete-install/g&amp;#39; /srv/scripts/horticulturalist/postrun/horticulturalist&amp;#34;&lt;/span>
sudo docker &lt;span style="color:#204a87">exec&lt;/span> -it medic-os /bin/bash -c &lt;span style="color:#4e9a06">&amp;#34;/boot/svc-disable medic-core openssh &amp;amp;&amp;amp; /boot/svc-disable medic-rdbms &amp;amp;&amp;amp; /boot/svc-disable medic-couch2pg&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The first command fixes a postrun script for horticulturalist to prevent unique scenarios of re-install. The second command removes extra services that you will not need.&lt;/p>
&lt;h3 id="visit-your-project">Visit your project&lt;/h3>
&lt;p>If you&amp;rsquo;re running this on your local machine, then open a browser to &lt;a href="https://localhost">https://localhost&lt;/a>. Otherwise open a browser to the public IP of the host if it&amp;rsquo;s running remotely.&lt;/p>
&lt;p>You will have to click to through the SSL Security warning. Click &amp;ldquo;Advanced&amp;rdquo; -&amp;gt; &amp;ldquo;Continue to site&amp;rdquo;.&lt;/p>
&lt;h3 id="clean-up-and-re-install">Clean up and re-install&lt;/h3>
&lt;p>If some instructions were missed and there&amp;rsquo;s a broken CHT deployment, use the commands below to start afresh:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Stop containers: &lt;code>docker stop medic-os &amp;amp;&amp;amp; docker stop haproxy&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Remove containers: &lt;code>docker rm medic-os &amp;amp;&amp;amp; docker rm haproxy&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Clean data volume:&lt;code>docker volume rm medic-data&lt;/code>&lt;/p>
&lt;p>Note: Running &lt;code>docker-compose -f docker-compose.yml down -v&lt;/code> would do all the above 3 steps&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Prune system: &lt;code>docker system prune&lt;/code>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>After following the above commands, you can re-run docker-compose up and create a clean install: &lt;code>docker-compose -f docker-compose.yml up -d&lt;/code>&lt;/p>
&lt;h3 id="port-conflicts">Port Conflicts&lt;/h3>
&lt;p>In case you are already running services on HTTP(80) and HTTPS(443),you will have to either remap ports to the medic-os container or stop the services using those ports.&lt;/p>
&lt;p>To find out which service is using a conflicting port: On Linux:&lt;/p>
&lt;p>&lt;code>sudo netstat -plnt | grep ':&amp;lt;port&amp;gt;'&lt;/code>&lt;/p>
&lt;p>On Mac (10.10 and above):&lt;/p>
&lt;p>&lt;code>sudo lsof -iTCP -sTCP:LISTEN -n -P | grep ':&amp;lt;port&amp;gt;'&lt;/code>&lt;/p>
&lt;p>You can either kill the service which is occupying HTTP/HTTPS ports, or run the container with forwarded ports that are free. In your compose file, change the ports under medic-os:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">services&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">medic-os&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">container_name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>medic-os&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">image&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>medicmobile/medic-os&lt;span style="color:#000;font-weight:bold">:&lt;/span>cht&lt;span style="color:#0000cf;font-weight:bold">-3.7.0&lt;/span>-rc&lt;span style="color:#0000cf;font-weight:bold">.1&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">volumes&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- medic-data&lt;span style="color:#000;font-weight:bold">:&lt;/span>/srv&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">ports&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#0000cf;font-weight:bold">8080&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">80&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- &lt;span style="color:#0000cf;font-weight:bold">444&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">443&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Turn off and remove all existing containers that were started:&lt;/p>
&lt;p>&lt;code>sudo docker-compose -f /path/to/docker-compose.yml down&lt;/code>&lt;/p>
&lt;p>Bring Up the containers in detached mode with the new forwarded ports.&lt;/p>
&lt;p>&lt;code>sudo docker-compose -f /path/to/docker-compose.yml up -d&lt;/code>&lt;/p>
&lt;p>Note: You can substitute 8080, 444 with whichever ports are free on your host. You would now visit https://localhost:444 to visit your project.&lt;/p>
&lt;h2 id="data-storage--persistence">Data storage &amp;amp; persistence&lt;/h2>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
Containers that are already set up will lose all data when following the steps below to remap the &lt;code>/srv&lt;/code> directory.
&lt;/div>
&lt;p>Docker containers are &lt;a href="https://www.redhat.com/en/topics/cloud-native-apps/stateful-vs-stateless">stateless&lt;/a> by design. In order to persist your data when a container restarts you need to specify the volumes that the container can use to store data. The CHT app stores all its data in the &lt;code>/srv&lt;/code> folder. This is the folder that you need to map to your volume before you spin up your containers.&lt;/p>
&lt;p>Ideally you should map this folder to a volume that is backed up regularly by your cloud hosting provider.&lt;/p>
&lt;p>The example below shows how to map this folder in Ubuntu:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Create the &lt;code>/srv&lt;/code> folder: &lt;code>sudo mkdir /srv&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Mount your volume to this folder: &lt;code>sudo mount /dev/xvdg /srv&lt;/code> . The attached volume number varies. Find your volume by running &lt;code>lsblk&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Update your compose file so that the containers store data to this folder&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">services&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">medic-os&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">container_name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>medic-os&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">image&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>medicmobile/medic-os&lt;span style="color:#000;font-weight:bold">:&lt;/span>cht&lt;span style="color:#0000cf;font-weight:bold">-3.9.0&lt;/span>-rc&lt;span style="color:#0000cf;font-weight:bold">.2&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">volumes&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- /srv&lt;span style="color:#000;font-weight:bold">:&lt;/span>/srv&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>---&lt;span style="color:#8f5902;font-style:italic">-
&lt;/span>&lt;span style="color:#8f5902;font-style:italic"> haproxy:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">container_name&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>haproxy&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">image&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>medicmobile/haproxy&lt;span style="color:#000;font-weight:bold">:&lt;/span>rc&lt;span style="color:#0000cf;font-weight:bold">-1.17&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">volumes&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- /srv&lt;span style="color:#000;font-weight:bold">:&lt;/span>/srv&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;p>Alternatively, can create the &lt;code>/srv&lt;/code> folder on any drive with enough space that is regularly backed up. Then map the path to the folder in the compose file like this.&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#204a87;font-weight:bold">volumes&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>- /path/to/srv&lt;span style="color:#000;font-weight:bold">:&lt;/span>/srv&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Be sure to check the available storage space regularly and expand your volume when needed&lt;/p>
&lt;h2 id="backup">Backup&lt;/h2>
&lt;p>Regular backups should be made of the &lt;code>/srv&lt;/code> directory to have holistic and easy to restore copies of all important data and the current CHT version installed. To backup just the data and not the CHT, make copies of &lt;code>/srv/storage/medic-core/&lt;/code>. This directory includes 4 key sub-directies:&lt;/p>
&lt;ul>
&lt;li>./couchdb&lt;/li>
&lt;li>./openssh&lt;/li>
&lt;li>./nginx&lt;/li>
&lt;li>./passwd&lt;/li>
&lt;/ul>
&lt;p>To make backups of just CouchDB data outside of the CHT docker infrastructure, please see &lt;a href="https://docs.couchdb.org/en/2.3.1/maintenance/backups.html">CouchDB&amp;rsquo;s Backup docs for 2.3.1&lt;/a>. Please note:&lt;/p>
&lt;ul>
&lt;li>CouchDB data files are in &lt;code>/srv/storage/medic-core/couchdb/data&lt;/code> in the &lt;code>medic-os&lt;/code> container.&lt;/li>
&lt;li>Backing up via replication is discouraged as restored DBs can cause offline users to restart replication from zero. Use file backups instead.&lt;/li>
&lt;/ul></description></item><item><title>Apps: App Developer Hosting</title><link>https://docs.communityhealthtoolkit.org/apps/guides/hosting/app-developer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/apps/guides/hosting/app-developer/</guid><description>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
&lt;p>This guide assumes you are a CHT app developer wanting to either run concurrent instances of the CHT, or easily be able to switch between different instances without loosing any data while doing so. To do development on the CHT core itself, see the &lt;a href="https://github.com/medic/cht-core/blob/master/DEVELOPMENT.md">development guide&lt;/a>.&lt;/p>
&lt;p>To deploy the CHT in production, see either &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/self-hosting/">AWS hosting&lt;/a> or &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/ec2-setup-guide/">Self hosting&lt;/a>&lt;/p>
&lt;/div>
&lt;h2 id="getting-started">Getting started&lt;/h2>
&lt;p>Be sure to meet the &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/requirements/">CHT hosting requirements&lt;/a> first. As well, if any other &lt;code>medic-os&lt;/code> instances using &lt;a href="https://github.com/medic/cht-core/blob/master/docker-compose.yml">the main &lt;code>docker-compose.yml&lt;/code> file&lt;/a> are running locally, stop them otherwise port, storage volume and container name conflicts may occur.&lt;/p>
&lt;p>After meeting these requirements, download the developer YAML file in the directory you want to store them:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">curl -o docker-compose-developer.yml https://raw.githubusercontent.com/medic/cht-core/master/docker-compose-developer.yml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>To start the first developer CHT instance, run &lt;code>docker-compose&lt;/code> and specify the file that was just download:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">docker-compose -f docker-compose-developer.yml up
&lt;/code>&lt;/pre>&lt;/div>&lt;p>This may take some minutes to fully start depending on the speed of the Internet connection and speed of the bare-metal host. This is because docker needs to download all the storage layers for all the containers and the CHT needs to run the first run set up. After downloads and setup has completed, the CHT should be accessible on &lt;a href="https://localhost">https://localhost&lt;/a>.&lt;/p>
&lt;p>When connecting to a new dev CHT instance for the first time, an error will be shown, &amp;ldquo;Your connection is not private&amp;rdquo; (see &lt;a href="https://docs.communityhealthtoolkit.org/apps/tutorials/local-setup/privacy.error.png">screenshot&lt;/a>). To get past this, click &amp;ldquo;Advanced&amp;rdquo; and then click &amp;ldquo;Proceed to localhost&amp;rdquo;.&lt;/p>
&lt;h2 id="running-the-nth-cht-instance">Running the Nth CHT instance&lt;/h2>
&lt;p>After running the first instance of the CHT, it&amp;rsquo;s easy to run as many more as are needed. This is achieved by specifying different:&lt;/p>
&lt;ul>
&lt;li>port for &lt;code>HTTP&lt;/code> redirects (&lt;code>CHT_HTTP&lt;/code>)&lt;/li>
&lt;li>port for &lt;code>HTTPS&lt;/code> traffic (&lt;code>CHT_HTTPS&lt;/code>)&lt;/li>
&lt;li>project to for the docker compose call (&lt;code>-p PROJECT&lt;/code>)&lt;/li>
&lt;/ul>
&lt;p>Assuming you want to start a new project called &lt;code>the_second&lt;/code> and start the instance on &lt;code>HTTP&lt;/code> port &lt;code>8081&lt;/code> and &lt;code>HTTPS&lt;/code> port &lt;code>8443&lt;/code>, this would be the command:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#000">CHT_HTTP&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">8081&lt;/span> &lt;span style="color:#000">CHT_HTTPS&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">8443&lt;/span> docker-compose -p the_second -f docker-compose-developer.yml up
&lt;/code>&lt;/pre>&lt;/div>&lt;p>The second instance is now accessible at &lt;a href="https://localhost:8443">https://localhost:8443&lt;/a>.&lt;/p>
&lt;h2 id="the-env-file">The &lt;code>.env&lt;/code> file&lt;/h2>
&lt;p>Often times it&amp;rsquo;s convenient to use revision control, like GitHub, to store and publish changes in a CHT app. A nice compliment to this is to store the specifics on how to run the &lt;code>docker-compose&lt;/code> command for each app. By using a shared &lt;code>docker-compose&lt;/code> configuration for all developers on the same app, it avoids any port collisions and enables all developers to have a unified configuration.&lt;/p>
&lt;p>Using the above &lt;code>the_second&lt;/code> sample project, we can create another directory to host this project&amp;rsquo;s configuration:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">mkdir ../the_second
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Create a file &lt;code>../the_second/.env-docker-compose&lt;/code> with this contents:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">&lt;span style="color:#000">COMPOSE_PROJECT_NAME&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>the_second
&lt;span style="color:#000">CHT_HTTP&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">8081&lt;/span>
&lt;span style="color:#000">CHT_HTTPS&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">8443&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Now it&amp;rsquo;s easy to boot this environment by specifying which &lt;code>.env&lt;/code> file to use:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-shell" data-lang="shell">docker-compose --env-file ../the_second/.env-docker-compose -f docker-compose-developer.yml up
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="switching--concurrent-projects">Switching &amp;amp; concurrent projects&lt;/h2>
&lt;p>The easiest way to switch between projects is to stop the first set of containers and start the second set. Cancel the first project running in the foreground with &lt;code>ctrl + c&lt;/code>. Then start the second project using either the &lt;code>.env&lt;/code> file or use the explicit command with ports and project name as shown above.&lt;/p>
&lt;p>To run projects concurrently, instead of cancelling the first one, open a second terminal and start the second project.&lt;/p>
&lt;p>To read more about how &lt;code>docker-compose&lt;/code> works, be sure to read the &lt;a href="https://docs.communityhealthtoolkit.org/core/guides/docker-setup/#helpful-docker-commands">helpful docker-compose commands&lt;/a> page.&lt;/p>
&lt;h2 id="cookie-collisions">Cookie collisions&lt;/h2>
&lt;p>The CHT stores its cookies based on the domain. This means if you&amp;rsquo;re running two concurrent instances on &lt;code>https://localhost&lt;/code> and &lt;code>https://localhost:8443&lt;/code>, the CHT would store the cookie under the same &lt;code>localhost&lt;/code> domain. When logging out of one instance, you would get logged out of both and other consistencies.&lt;/p>
&lt;p>To avoid this collision of cookies, you can use different IP addresses to access the instances. This works because the IPs that are available to reference &lt;code>localhost&lt;/code> are actually a &lt;code>/8&lt;/code> netmask, meaning &lt;a href="https://en.wikipedia.org/wiki/Localhost#Name_resolution">there are 16 million addresses&lt;/a> to choose from!&lt;/p>
&lt;p>Using the above two configurations, these URLs could work to avoid the cookie colission:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://127.0.0.1">https://127.0.0.1&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://127.0.0.2:8443">https://127.0.0.2:8443&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>This would result in the domains being &lt;code>127.0.0.1&lt;/code> and &lt;code>127.0.0.2&lt;/code> from the CHT&amp;rsquo;s perspective.&lt;/p></description></item><item><title>Apps: SSL Cert Install</title><link>https://docs.communityhealthtoolkit.org/apps/guides/hosting/ssl-cert-install/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/apps/guides/hosting/ssl-cert-install/</guid><description>
&lt;h2 id="requirements">Requirements&lt;/h2>
&lt;ul>
&lt;li>Installed CHT-Core 3.x via either &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/self-hosting/">Self Hosted&lt;/a>, &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/ec2-setup-guide/">EC2&lt;/a> or &lt;a href="https://docs.communityhealthtoolkit.org/apps/tutorials/local-setup/">Local Setup&lt;/a>, but must use &lt;code>docker-compose&lt;/code>.&lt;/li>
&lt;li>Your own SSL certifications like Let&amp;rsquo;s Encrypt.&lt;/li>
&lt;/ul>
&lt;h2 id="copy-certs-into-medic-os-container">Copy certs into medic-os container&lt;/h2>
&lt;p>On your server copy the &lt;code>.crt&lt;/code> and &lt;code>.key&lt;/code> files to the &lt;code>medic-os&lt;/code> container. The existing self signed &lt;code>.crt&lt;/code> and &lt;code>.key&lt;/code> files will be overwitten:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">sudo docker cp /path/to/ssl.crt medic-os:/srv/settings/medic-core/nginx/private/default.crt
sudo docker cp /path/to/ssl.key medic-os:/srv/settings/medic-core/nginx/private/default.key
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="restart-services">Restart services&lt;/h2>
&lt;p>Now that the &lt;code>.crt&lt;/code> and &lt;code>.key&lt;/code> files are in place, restart &lt;code>nginx&lt;/code> in the &lt;code>medic-os&lt;/code> container with:&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">docker &lt;span style="color:#204a87">exec&lt;/span> -it medic-os /boot/svc-restart medic-core nginx
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="view-nginx-logs">View Nginx Logs&lt;/h2>
&lt;p>To troubleshoot any problems with the new certificates, after running &lt;code>docker exec -it medic-os bash&lt;/code>, the &lt;code>nginx&lt;/code> log files can be found in &lt;code>/srv/storage/medic-core/nginx/logs/&lt;/code>, including:&lt;/p>
&lt;ul>
&lt;li>access.log&lt;/li>
&lt;li>error-ssl.log&lt;/li>
&lt;li>error.log&lt;/li>
&lt;li>startup.log&lt;/li>
&lt;/ul></description></item><item><title>Apps: Offline Hosting of CHT Server</title><link>https://docs.communityhealthtoolkit.org/apps/guides/hosting/offline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://docs.communityhealthtoolkit.org/apps/guides/hosting/offline/</guid><description>
&lt;div class="alert alert-primary" role="alert">
&lt;h4 class="alert-heading">Note&lt;/h4>
&lt;p>This guide is not meant for a production CHT instance. Support may be added in the future an offline CHT server in a production environment. Please see the &amp;ldquo;Considerations&amp;rdquo; section below.&lt;/p>
&lt;p>Proceed only if you have staff familiar with DNS, TLS Certs, DHCP, LAN topology and Linux in general. This is a complex deployment where mistakes are easy to make unless proper training is in place.&lt;/p>
&lt;/div>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>The CHT is built as an &lt;a href="https://docs.communityhealthtoolkit.org/core/overview/offline-first/">Offline-First&lt;/a> application. This applies to clients, either browsers or Android applications, connecting to the CHT server. The server itself assumes it has Internet connectivity to provide services such as DNS, software updates and general use connectivity. This document explores what it looks like when the CHT server is offline without these services available.&lt;/p>
&lt;p>Running a CHT server offline requires no modifications to the CHT itself. Instead, supporting services normally found online are replicated locally.&lt;/p>
&lt;h2 id="considerations">Considerations&lt;/h2>
&lt;p>An offline CHT server is most appropriate for a development environment. There are serious implications to consider before deploying an offline instance per our &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/requirements/#considerations">existing requirements&lt;/a>.&lt;/p>
&lt;p>Additionally, if users are going to migrate between offline locations with the same domain name, always ensure different login and passwords are used for all users across instances. This will prevent a client from another CHT instance trying to synchronize with a CHT instance it shouldn&amp;rsquo;t synchronize with, possibly causing data corruption or privacy issues through unintended data access.&lt;/p>
&lt;h2 id="requirements">Requirements&lt;/h2>
&lt;p>A CHT instance is accessible offline when you can resolve the domain to an IP address, and a TLS certificate is on the CHT server with a common name (CN) that matches the domain name. On top of the &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/requirements/">existing requirements&lt;/a>, the following aspects must also be considered.&lt;/p>
&lt;h3 id="static-ip">Static IP&lt;/h3>
&lt;p>The CHT server needs to be given a static IP so that DNS will always resolve to the correct host.&lt;/p>
&lt;h3 id="tls-certificate">TLS Certificate&lt;/h3>
&lt;p>Browsers might allow you to connect to a server with an invalid TLS certificate after you &lt;a href="https://www.ssl.com/guide/troubleshooting-ssl-tls-browser-errors-and-warnings/">bypass the warning&lt;/a>. Android apps however, like &lt;a href="https://github.com/medic/cht-android">CHT Android App&lt;/a>, require a valid TLS certificate to work correctly, therefore you would need to acquire a valid TLS certificate from a certificate authority (CA) and install it on your CHT server.&lt;/p>
&lt;p>It is common to use &lt;a href="https://en.wikipedia.org/wiki/Let%27s_encrypt">Let&amp;rsquo;s Encrypt&lt;/a> to acquire certificates because they provide free certificates. Let&amp;rsquo;s Encrypt certificates expire after 90 days, so the server will need to be constantly updated with a new certificate. Other CAs provide certificates that expire after a year, so this concern will always apply.&lt;/p>
&lt;p>After acquiring the certificate, if you are running a Docker-based CHT deployment, see &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/hosting/ssl-cert-install/">TLS instructions for Docker&lt;/a> to install the certificate.&lt;/p>
&lt;h3 id="domain-name-server">Domain Name Server&lt;/h3>
&lt;p>In order to match the static IP of the web server to the CN in the certificate, a Domain Name Server (DNS) must be used. This will allow any client on the LAN to easily connect to your CHT server without needing anything more than the domain name.&lt;/p>
&lt;p>Most LANs will defer to the Internet Service Provider (ISP) to provide DNS, but there is no ISP in an offline scenario. Instead, one must be provided. This DNS server will then be configured to have an &lt;code>A&lt;/code> record (or &lt;code>AAAA&lt;/code> in the case of IPv6) to point to the CHT server.&lt;/p>
&lt;h3 id="dynamic-host-configuration-protocol">Dynamic Host Configuration Protocol&lt;/h3>
&lt;p>Any new client that connects to a network will get an IP address from a Dynamic Host Configuration Protocol (DHCP) server. It is critical that the DHCP server for the LAN the CHT is on instructs all clients to use the DNS server configured above.&lt;/p>
&lt;h3 id="wi-fi-ap">Wi-Fi AP&lt;/h3>
&lt;p>A Wi-FI Access Point (AP) needs to be deployed on the LAN so Android devices can connect to the CHT. This can be an AP included with the router or a standalone AP. If the AP is standalone, check that any DHCP or DNS servers that could conflict with the one above are disabled.&lt;/p>
&lt;h2 id="benefits-over-other-solutions">Benefits Over Other Solutions&lt;/h2>
&lt;p>An offline deployment may consider substituting some requirements above with these other solutions. Note that ngrok and local-ip.co require Internet connectivity, so are not an offline solution.&lt;/p>
&lt;h3 id="ngrok">ngrok&lt;/h3>
&lt;p>When an offline solution is deployed, traffic stays 100% local, whereas when using either &lt;a href="https://docs.communityhealthtoolkit.org/apps/guides/debugging/secure-sharing-of-developer-instance/">your own reverse proxy&lt;/a> or a third party provider like &lt;a href="https://ngrok.com/">ngrok&lt;/a>, traffic may traverse 100s or 1,000s of kilometers to ultimately reach the CHT server which is 10 meters away. This can help when Internet connectivity is very slow, very expensive per megabyte, or both.&lt;/p>
&lt;h3 id="local-ipco">local-ip.co&lt;/h3>
&lt;p>&lt;a href="http://local-ip.co/">local-ip.co&lt;/a> offers both the TLS certificate and private key for &lt;code>*.my.local-ip.co&lt;/code>. Additionally, the service has a DNS server that dynamically maps any IP you pass in the sub-sub-domain to the real world IP such that &lt;code>192-168-0-1.my.local-ip.co&lt;/code> would resolve to &lt;code>192.168.0.1&lt;/code>. This can make it very handy to deploy a development instance where all HTTP traffic remains local (unlike &lt;code>ngrok&lt;/code> above).&lt;/p>
&lt;p>As the DNS traffic still needs to leave your network and return, it is not a viable solution for a truly offline CHT deployment.&lt;/p>
&lt;h3 id="self-signed-certificates">Self-Signed Certificates&lt;/h3>
&lt;p>Another option to consider is to &lt;a href="https://gist.github.com/anand-k-p/851e57c3aa43e1e36df164f1c215609e">self-sign the certificates&lt;/a> and then either bypass the warnings in browsers or install the new CA root certificate on your devices. While this may work for a development environment with a single developer, it will be hard to scale to an environment where you&amp;rsquo;d like to easily provision many Android devices. The work will be much more than just installing an APK form the Play Store (or the slightly harder side load process).&lt;/p>
&lt;p>This may only work on certain, older version of Android as well.&lt;/p>
&lt;h3 id="no-dhcp-or-dns-server">No DHCP or DNS Server&lt;/h3>
&lt;p>To avoid installing both the DHCP and DNS servers, an Android app that enables custom DNS entries, like &lt;a href="https://play.google.com/store/apps/details?id=com.burakgon.dnschanger">DNS Changer&lt;/a> or &lt;a href="https://play.google.com/store/apps/details?id=org.itxtech.daedalus">Daedalus&lt;/a> could be used. As &lt;a href="https://stackoverflow.com/questions/6370017/mapping-a-hostname-to-an-ip-address-on-android">seen here&lt;/a>, on each Android device you could install this and add custom DNS entries to reach the TLS certificate on the CHT.&lt;/p>
&lt;p>Like the self-signed certificate solution, this is hard to scale and would need to be complimented by editing &lt;code>/etc/hosts&lt;/code> files on desktop browsers.&lt;/p></description></item></channel></rss>